{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df6c603",
   "metadata": {},
   "source": [
    "# Tutorial 6: Basics of netCDF file manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd7905",
   "metadata": {},
   "source": [
    "In previous tutorials, we've worked with discrete data such as hourly air quality measurements. In this tutorial, we'll move beyond discrete data into continuous or gridded data. This method can  be used with model data, reanalysis data, satellite data, or any dataset that is continuous or gridded over the area of interest.   \n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "* open netCDF files with Xarray\n",
    "* distinguish between code for DataArrays and Datasets\n",
    "* identify the properties of an Xarray DataArray and Dataset\n",
    "* create a plot using continuous or gridded data\n",
    "* manipulate data using array properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f5300",
   "metadata": {},
   "source": [
    "### How to deal with 2D or 3D data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2ecaf",
   "metadata": {},
   "source": [
    "So far, we've worked with lists and tables, which are examples of 1D (lists) and simple 2D (tables) data. But what if we have more complex 2D data, or even 3D data? pandas can no longer handle this type of information. Instead, we use other packages like *Xarray*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f625ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation and opening files\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee36c1c",
   "metadata": {},
   "source": [
    "<font color=red> **Note:**</font> If you get an error message saying that you do not have the necessary libraries, such as h5netcdf or pseudonetcdf, then you will need to install them. To do this, follow these instructions:\n",
    "1. Open either a new terminal window (Mac) or Anaconda prompt (PC).\n",
    "2. Copy and paste `conda install -c conda-forge netCDF4`.\n",
    "3. Hit enter.\n",
    "4. When prompted, hit `y`.\n",
    "5. Once the installation is complete, repeat steps 2-4 for all necessary libraries. These may include h5netcdf, PyNIO, h5py, and PseudoNetCDF. If they are already installed, conda will tell you the package is up-to-date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a1fb9",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "\n",
    "Files of large gridded datasets can be too large to easily share. Instead, you will need to access the data yourself using the following steps. In later tutorials, we will show more ways to download data with Python code and ways to work with cloud-based data. \n",
    "\n",
    "1. Go to https://www.ncei.noaa.gov/access/world-ocean-atlas-2018/. \n",
    "2. Play around with the different data available. There are several ocean data products. For this tutorial, we will be using sea surface temperature. The code examples will be specific to this data, but you can choose any data product and just change the variable names.    \n",
    "3. Once you have selected a data product from the left hand menu, click \"netCDF\" under available data formats. Choose a time period of interest. This tutorial uses the 2005-2017 summer period. Click \"Update data links\" at the bottom of the left hand menu.\n",
    "    - **Reminder:** If you choose to work with a different data product, year, or grid size, you will need to change the file link below and the variable names. \n",
    "4. On the right hand side, select the Annual data link, t15_01.nc. This will take you to the THREDDS Server page.\n",
    "5. Click the OPeNDAP URL option (top link in the list). \n",
    "6. Copy the Data URL on the OPeNDAP page. \n",
    "7. Paste the URL below in the `file = 'https://` line. Change any other variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5396e",
   "metadata": {},
   "source": [
    "### Opening files with xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb57189",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/temperature/A5B7/1.00/woa18_A5B7_t15_01.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xarray to open the file you chose\n",
    "data = xr.open_dataset(file,engine='netcdf4',decode_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83437bd6",
   "metadata": {},
   "source": [
    "Xarray can be described as a multi-dimensional version of pandas. Like pandas, the data can be indexed and sorted based on location or name. However, Xarray can do these things with data of three dimensions or more. Let's explore some of the ways Xarray organizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this data look like? This line of code may take a second to run - don't worry!\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16716d",
   "metadata": {},
   "source": [
    "Ok, there's a lot going on here. Let's break these different things down a bit.    \n",
    "\n",
    "**Array Type:** The very first thing that is shown in the above print out is 'xarray.Dataset'. There are two main types of arrays that xarray can handle: DataArrays and Datasets. A Dataset is a collection of DataArrays. Imagine that a DataArray is a rubix cube. It is a 3D (or 2D or 4D or however shaped) array of data. A Dataset would therefore be a collection of rubix cubes. Imagine you ordered a shipment of 30 rubix cubes. Each individual rubix cube is a DataArray, and the box that all the cubes were shipped in is the Dataset. We can select one DataArray using its variable name. There are some data selection methods that only work on DataArrays, which is why it is important to distinguish between DataArrays and Datasets.\n",
    "\n",
    "**Dimensions:** The dimensions are the directions that the file has, or the names of the axes. There are four dimensions listed in this file: lat, lon, depth, and time. Since this is ocean data, we can think of these as latitudes or rows and longitudes or columns. There are 180 rows, which means there are 180 lines of latitude in the grid. There are 360 columns, or 360 lines of longitude. The depth dimension is 102, meaning that there are 102 vertical layers in the data. Oceans have depth, rather than height, so these layers will extend from the surface downward. Finally, there is time dimension.  \n",
    "\n",
    "**Coordinates:** Coordinates are labels for each step of a dimension. This particular file has the same four coords as dimensions: lat, lon, depth, and time. Each step in the lat coord has a new value (the latitude coordinate on a map), each step in the lon coord has a new value (the longitude coordinate on a map), each depth step has a new value, but there is only one time coordinate. This is because the dataset uses an unusual time parameter: months since the start date. In this case, the start date is 2005-01-01, and the dataset is saying there are 726 months since that start date in the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cffe88",
   "metadata": {},
   "source": [
    "**Data Variables:** These are the variables of interest. This is the actual data in your file. For example, in this file there is \"t_an\" that might be of interest to us. In some datasets, the data variables have unusual names, which can make understanding the data difficult. Xarray is great because it allows you to have metadata for each data variable, which might help to explain the data a little more. Click on the picture of a piece of paper next to the \"t_an\" variable name. What does it say? Some of the data variables have useful metadata under this piece of paper.    \n",
    "Next, click on the picture of 3 stacked circles beside a data variable. What should appear is an array of the data. These are the actual values of this data variable.  \n",
    "\n",
    "**Attributes:** Finally, Xarray has more metadata stored in the Attributes. Some of this information can be helpful, such as the time_coverage_start or the geospatial_lat_max. Knowing the start and end dates of your data is super important, and knowing the map projection is important for properly formatting the data for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331ba28",
   "metadata": {},
   "source": [
    "If you are interested in knowing just the attributes or just the coordinates or just the dims of an Xarray DataArray, you can call this information specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we call the dimensions using the key word \"dims\"\n",
    "data.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we call the coordinates using the key word \"coords\"\n",
    "data.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we use the key word \"attrs\". Can you guess what this key word calls?\n",
    "data.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we call the data variables using the key word \"var\"\n",
    "data.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93f0ec",
   "metadata": {},
   "source": [
    "### Selecting and indexing data\n",
    "\n",
    "Remember earlier when we said that DataArrays and Datasets are different? Indexing and selecting data is one of the places that distinguish DataArrays and Datasets. Right now, we have a Dataset. This is a collection of DataArrays. We can select one of these arrays using the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3935ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a DataArray from our Dataset\n",
    "# like using column names in pandas, we can select specific DataArrays using the array variable name\n",
    "var = data['t_an']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de8425",
   "metadata": {},
   "source": [
    "**Knowledge Check:** How is this print out different from the print out of data? Why is it different? Take a moment here to really think through the differences between var and data and what they mean. Some information you might want to think about for the next few code cells:\n",
    "1. What type array is this?\n",
    "2. How many dimensions are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7272",
   "metadata": {},
   "source": [
    "The biggest difference between var and data is that var is only one variable from the dataset, but data has all the data variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68700aaa",
   "metadata": {},
   "source": [
    "Like pandas, there are several ways to select data in Xarray. We can select the dimension of the data using positions or using names. Using positions, this is like saying \"I want the data in axis 1\". Using names, this is like saying \"I want the data in the longitude\". For either of these methods, you can use an integer or a label to select the index. We'll try a few examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb738c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional indexing of dimensions using integers\n",
    "# translation: use a number to select the axis\n",
    "var[0,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3792c2",
   "metadata": {},
   "source": [
    "In the example above, we used square brackets ```[]``` to say \"Take the dims of this DataArray.\" We then used colons ```:``` to say \"Take all points in this dimension\" and an integer ``0`` to say \"take the 0th point in this dimension.\" The code ```var[0,:,:,:]``` therefore is saying \"Take only the first time value, but all the values in the depth, lat, and lon.\" You can see how this was done by looking at the new dims of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f57af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension name indexing using integers\n",
    "var.isel(lon=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0360c",
   "metadata": {},
   "source": [
    "In this example, we used the `isel` (integer select) command to select only the 0th layer of the DataArray. This is the same result as the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329838db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to index using dimension names and integers\n",
    "var[dict(lon=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc50a6e",
   "metadata": {},
   "source": [
    "You should now be able to see how Xarray, like pandas, has multiple methods to select and index data. This is only true for DataArrays. Datasets, because they are more complex, cannot be indexed using positions. Dimension names must be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e826a37",
   "metadata": {},
   "source": [
    "Next, let's slice our data.  \n",
    "A slice is what it sounds like: it is a piece of the data that we are cutting out from the whole. `slice(None, 3)` says \"Cut a piece of this data, starting at the 0th position (None) and ending at the 3rd position (3).\" We used the dimension name \"lon\" to tell xarray which dimension to index on. So `lon=slice(None,3)` is saying \"Cut a piece of the lon data, starting at the 0th position and ending at the 3rd position.\" This is how we cut out the first 3 lons of the data.   \n",
    "In the cell below, we print out the dimensions of the original data and of some sliced data. Do the dimensions printed match your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dims)\n",
    "print(data[dict(lat=slice(None, 30))].dims)\n",
    "print(data[dict(lon=slice(25,100))].dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe3ee9",
   "metadata": {},
   "source": [
    "**Knowledge Check:** If you see code that has square brackets `data[:]`, is that code selecting data using positional indexing or dimension name indexing? Which type of array can use this indexing method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea32735",
   "metadata": {},
   "source": [
    "Like pandas, `[:]` indicates you are using positional indexing. The brackets say \"of all the data, select based on the following positions\", and the colon says \"go from this first position to this last position when selecting the data\". In Xarray, only a DataArray can use positional indexing. For a Dataset, you must use dimension names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950aaa4b",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "Now that we know how to select the data of interest, let's work on visualizing our data. Xarray has built-in plotting abilities, but these abilities are shortcuts of the same Matplotlib commands we learned in tutorials 3 and 4. To be more explicit in how we are visualizing and manipulating the data, we will continue to use the Matplotlib commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a variable of interest for plotting\n",
    "temp = data['t_an']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e78b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376bd03",
   "metadata": {},
   "source": [
    "This data is the concentration of chlorophyll-a in the ocean as measured by reflection captured by the MODIS instrument on the Aqua satellite. The dimensions of the data are lat and lon, there is no height dimension. Therefore, we could plot this data of rows (latitudes) and columns (longitudes) using a grid that is 4320 x 8640, or we could make line plots of average concentrations over one of these dimensions. \n",
    "\n",
    "If you're having a hard time visualizing the data at this point, it might be helpful to go back to NASA WorldView and plot your data on the map. Go to https://worldview.earthdata.nasa.gov/ and search through the +Layers option to find your data. Then use the scroll bar at the bottom left to change the date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b725c7",
   "metadata": {},
   "source": [
    "What if we wanted to know the average concentration along a latitude or longitude? Perhaps we have the hypothesis that chlorophyll-a concentration is higher at lower latitudes closer to the equator. How would we test this hypothesis? We could take the mean of the data along the axis of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d493fc1",
   "metadata": {},
   "source": [
    "The chlorophyll-a data is formatted in a 2D array, and we want to take the average along one of these dimensions. If we want to know the average at each latitude, then we must take the mean along the column dimension. If this is hard to visualize, think back to a rubix cube. We want to know the average at each point along the y-axis (the rows). In order to do this, we must smush the x-axis, so take the average of the columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d5de6",
   "metadata": {},
   "source": [
    "Once again, we can using different indexing methods in Xarray to accomplish the same task. Now let's plot the averages, this time using Xarray plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96172d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the rows (latitudes) using integers\n",
    "lat_means = temp.mean(axis=2)\n",
    "lat_means.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the rows (latitudes) using dimension names\n",
    "lat_means2 = temp.mean('lat')\n",
    "lat_means2.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "lat_means.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f6310",
   "metadata": {},
   "source": [
    "Conveniently, Xarray plotting can use the dimensions and the data variables to correctly label the axes. However, these labels aren't the best for professional presentations, so you can still use Matplotlib commands to clean up the figure. Also, this figure seems backwards, right? Depth is in meters from the surface, so the smallest values of depth are actually the surface! This whole plot is upside down! How can we fix that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ec38f",
   "metadata": {},
   "source": [
    "One easy method is to simply invert the depth values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8428285",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.assign_coords({\"depth\": temp['depth'] * -1})\n",
    "lat_means = temp.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd81600",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "lat_means.plot()\n",
    "plt.title('Summertime Average Ocean Temperature 2005-2017')\n",
    "# you can change the label data for your data\n",
    "plt.xlabel('Latitude (˚)',fontsize=12)\n",
    "plt.ylabel('Depth (m)',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4438e1",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cef50",
   "metadata": {},
   "source": [
    "So far, we've been manipulating data from one Dataset of data collected on one season - summer. What if we want to look at data from more than one season? Can we merge two or more datasets together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54166720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, open another dataset\n",
    "file2 = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/temperature/A5B7/1.00/woa18_A5B7_t13_01.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcec5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xarray to open the file you chose\n",
    "data2 = xr.open_dataset(file2,engine='netcdf4',decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ac853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988ad62",
   "metadata": {},
   "source": [
    "At first glance, this Dataset looks pretty similar to the first Dataset. The dimensions, coordinates, and data variables are the same. Let's combine this Dataset with the first Dataset, but create a new \"date\" dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = xr.concat([data,data2],dim='season')\n",
    "merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf44e64c",
   "metadata": {},
   "source": [
    "We now have one larger Dataset that includes data and data2. These two original Datasets are differentiated by their position in the season dimension. We can label the season by assigning coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of season labels\n",
    "seasons = ['summer','winter']\n",
    "merge = merge.assign_coords(season=seasons)\n",
    "merge.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0abe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the labels of the coords can be pandas datetimes\n",
    "# change dates for your data, and comment out the methods that don't work for you\n",
    "\n",
    "# if you have consecutive days, you can use pd.date_range\n",
    "dates = pd.date_range('07-04-2022','07-05-2022') \n",
    "\n",
    "# if you have non-consecutive days, but if they repeat in a sequence, you can still use pd.date_range\n",
    "# just specify the frequency of the day intervals\n",
    "dates = pd.date_range('07-04-2022','07-05-2022',freq='1D') # change the number before D (day)\n",
    "\n",
    "# if you have completely random days, you can make a list of dates then use pd.to_datetime\n",
    "date_list = ['07-04-2022','07-05-2022']\n",
    "dates = pd.to_datetime(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc342e15",
   "metadata": {},
   "source": [
    "There are now 5 total dimensions in the Dataset, with \"season\" being the last dimension. This new Dataset is the combination of the two individual Datasets. In the following exercises, you will practice indexing this new Dataset and merging another file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f96b9",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b4afd",
   "metadata": {},
   "source": [
    "**1.** Select a subset of data from the merge Dataset that is   \n",
    "a) all seasons, the first 200 longitudes, and all latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda2003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34cd2e22",
   "metadata": {},
   "source": [
    "b) all season, all latitudes, longitudes 100 to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fc8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c41b46",
   "metadata": {},
   "source": [
    "c) all seasons, the 3rd longitude, latitudes 20 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ef638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a26eab3e",
   "metadata": {},
   "source": [
    "**2.** Select the t_an data from the merge Dataset. Find the following means of this DataArray.   \n",
    "a) Mean of the latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab233407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8d4494",
   "metadata": {},
   "source": [
    "b) Mean of the longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf3a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c116a173",
   "metadata": {},
   "source": [
    "c) Mean of each season (2 data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcafe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a442fd1",
   "metadata": {},
   "source": [
    "**3.** Open a third Dataset for a new season. Merge this Dataset with the first two Datasets along the season dimension. There are a few ways to do this, but the easiest way is to create a new Dataset using the `concat` command and list all three date files in the brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d25336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a new Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68182e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the three date Datasets together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12837322",
   "metadata": {},
   "source": [
    "**4.** Find the seasonal temperature from the 3 merged dates along the depth axis. Plot the three seasons as line plots of temperature versus depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803fe18",
   "metadata": {},
   "source": [
    "### Possible Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a\n",
    "subset = merge[dict(lon=slice(None,200))]\n",
    "subset.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b\n",
    "subset = merge[dict(lon=slice(100,200))]\n",
    "subset.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c\n",
    "subset = merge[dict(lon=3,lat=slice(20,50))]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7916fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "var = merge['t_an']\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c008676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a\n",
    "var.mean('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbe292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b\n",
    "var.mean('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c\n",
    "var.mean(['lat','lon','depth','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0718fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "file3 = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/temperature/A5B7/1.00/woa18_A5B7_t14_01.nc'\n",
    "data3 = xr.open_dataset(file3,engine='netcdf4',decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmerge = xr.concat([data,data2,data3],dim='season')\n",
    "bigmerge.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "temp = bigmerge['t_an'].assign_coords({\"depth\": bigmerge['depth'] * -1})\n",
    "summer = temp[dict(season=0)].mean(axis=(0,2,3))\n",
    "winter = temp[dict(season=1)].mean(axis=(0,2,3))\n",
    "fall = temp[dict(season=2)].mean(axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(summer)\n",
    "plt.plot(winter)\n",
    "plt.plot(fall)\n",
    "plt.ylabel('Temperature (˚C)',fontsize=12)\n",
    "plt.xlabel('Depth (m)',fontsize=12)\n",
    "plt.title('Seasonal average temperature',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
